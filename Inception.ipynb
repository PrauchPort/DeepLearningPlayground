{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13582797715877038074\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4945621811\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15868177172779264386\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_random_seed(22)\n",
    "np.random.seed(22)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train.astype(np.float32)/255., x_test.astype(np.float32)/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = np.expand_dims(x_train, axis=3), np.expand_dims(x_test, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(256)\n",
    "db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBNRelu(keras.Model):\n",
    "    \n",
    "    def __init__(self, ch, kernelsz=3, strides=1, padding='same'):\n",
    "        super(ConvBNRelu, self).__init__()\n",
    "        \n",
    "        self.model = keras.models.Sequential([\n",
    "            keras.layers.Conv2D(ch, kernelsz, strides=strides, padding=padding),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU()\n",
    "        ])\n",
    "        \n",
    "    def call(self, x, training=None):\n",
    "        \n",
    "        x = self.model(x, training=training)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class InceptionBlk(keras.Model):\n",
    "    \n",
    "    def __init__(self, ch, strides=1):\n",
    "        super(InceptionBlk, self).__init__()\n",
    "        \n",
    "        self.ch = ch\n",
    "        self.strides = strides\n",
    "        \n",
    "        self.conv1 = ConvBNRelu(ch, strides=strides)\n",
    "        self.conv2 = ConvBNRelu(ch, kernelsz=3, strides=strides)\n",
    "        self.conv3_1 = ConvBNRelu(ch, kernelsz=3, strides=strides)\n",
    "        self.conv3_2 = ConvBNRelu(ch, kernelsz=3, strides=1)\n",
    "        \n",
    "        self.pool = keras.layers.MaxPooling2D(3, strides=1, padding='same')\n",
    "        self.pool_conv = ConvBNRelu(ch, strides=strides)\n",
    "    \n",
    "    def call(self, x, training=None):\n",
    "        \n",
    "        x1 = self.conv1(x, training=training)\n",
    "        \n",
    "        x2 = self.conv2(x, training=training)\n",
    "        \n",
    "        x3_1 = self.conv3_1(x, training=training)\n",
    "        x3_2 = self.conv3_2(x3_1, training=training)\n",
    "        \n",
    "        x4 = self.pool(x)\n",
    "        x4 = self.pool_conv(x4, training=training)\n",
    "        \n",
    "        x = tf.concat([x1, x2, x3_2, x4], axis=3)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(keras.Model):\n",
    "    \n",
    "    def __init__(self, num_layers, num_classes, init_ch=16, **kwargs):\n",
    "        super(Inception, self).__init__(**kwargs)\n",
    "        \n",
    "        self.in_channels = init_ch\n",
    "        self.out_channels = init_ch\n",
    "        self.num_layers = num_layers\n",
    "        self.init_ch = init_ch\n",
    "        \n",
    "        self.conv1 = ConvBNRelu(init_ch)\n",
    "        \n",
    "        self.blocks = keras.models.Sequential(name='dynamic-blocks')\n",
    "        \n",
    "        for block_id in range(num_layers):\n",
    "            \n",
    "            for layer_id in range(2):\n",
    "                \n",
    "                if layer_id == 0:\n",
    "                    \n",
    "                    block = InceptionBlk(self.out_channels, strides=2)\n",
    "                    \n",
    "                else:\n",
    "                    block = InceptionBlk(self.out_channels, strides=1)\n",
    "                    \n",
    "                self.blocks.add(block)\n",
    "            \n",
    "            # enlarger out_channels per block    \n",
    "            self.out_channels *= 2\n",
    "            \n",
    "        self.avg_pool = keras.layers.GlobalAveragePooling2D()\n",
    "        self.fc = keras.layers.Dense(num_classes)\n",
    "        \n",
    "        \n",
    "    def call(self, x, training=None):\n",
    "        \n",
    "        out = self.conv1(x, training=training)\n",
    "        \n",
    "        out = self.blocks(out, training=training)\n",
    "        \n",
    "        out = self.avg_pool(out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out   \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\wojtek\\appdata\\local\\conda\\conda\\envs\\deep learning\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_bn_relu (ConvBNRelu)    multiple                  224       \n",
      "_________________________________________________________________\n",
      "dynamic-blocks (Sequential)  multiple                  292704    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  1290      \n",
      "=================================================================\n",
      "Total params: 294,218\n",
      "Trainable params: 293,226\n",
      "Non-trainable params: 992\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "model = Inception(2, 10)\n",
    "model.build(input_shape=(None, 28, 28, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\wojtek\\appdata\\local\\conda\\conda\\envs\\deep learning\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "0 0 loss: 2.3067923\n",
      "0 evaluation_acc: 0.101\n",
      "0 evaluation_acc: 0.2116\n",
      "0 evaluation_acc: 0.2668\n",
      "0 evaluation_acc: 0.2661\n",
      "0 evaluation_acc: 0.127\n",
      "0 evaluation_acc: 0.1057\n",
      "0 evaluation_acc: 0.2288\n",
      "0 evaluation_acc: 0.2727\n",
      "0 evaluation_acc: 0.3359\n",
      "0 evaluation_acc: 0.2651\n",
      "0 10 loss: 2.096843\n",
      "0 evaluation_acc: 0.3241\n",
      "0 evaluation_acc: 0.2838\n",
      "0 evaluation_acc: 0.4292\n",
      "0 evaluation_acc: 0.3161\n",
      "0 evaluation_acc: 0.5057\n",
      "0 evaluation_acc: 0.353\n",
      "0 evaluation_acc: 0.3798\n",
      "0 evaluation_acc: 0.3829\n",
      "0 evaluation_acc: 0.4507\n",
      "0 evaluation_acc: 0.4559\n",
      "0 20 loss: 1.575044\n",
      "0 evaluation_acc: 0.5273\n",
      "0 evaluation_acc: 0.5856\n",
      "0 evaluation_acc: 0.5214\n",
      "0 evaluation_acc: 0.4537\n",
      "0 evaluation_acc: 0.3371\n",
      "0 evaluation_acc: 0.5629\n",
      "0 evaluation_acc: 0.5271\n",
      "0 evaluation_acc: 0.5461\n",
      "0 evaluation_acc: 0.5191\n",
      "0 evaluation_acc: 0.4959\n",
      "0 30 loss: 1.3221254\n",
      "0 evaluation_acc: 0.5709\n",
      "0 evaluation_acc: 0.6111\n",
      "0 evaluation_acc: 0.6307\n",
      "0 evaluation_acc: 0.5961\n",
      "0 evaluation_acc: 0.6275\n",
      "0 evaluation_acc: 0.6255\n",
      "0 evaluation_acc: 0.6753\n",
      "0 evaluation_acc: 0.766\n",
      "0 evaluation_acc: 0.7423\n",
      "0 evaluation_acc: 0.7348\n",
      "0 40 loss: 0.8555263\n",
      "0 evaluation_acc: 0.712\n",
      "0 evaluation_acc: 0.6808\n",
      "0 evaluation_acc: 0.7761\n",
      "0 evaluation_acc: 0.6994\n",
      "0 evaluation_acc: 0.765\n",
      "0 evaluation_acc: 0.8056\n",
      "0 evaluation_acc: 0.7071\n",
      "0 evaluation_acc: 0.6924\n",
      "0 evaluation_acc: 0.5286\n",
      "0 evaluation_acc: 0.8015\n",
      "0 50 loss: 0.73821545\n",
      "0 evaluation_acc: 0.7029\n",
      "0 evaluation_acc: 0.7869\n",
      "0 evaluation_acc: 0.7501\n",
      "0 evaluation_acc: 0.7621\n",
      "0 evaluation_acc: 0.7465\n",
      "0 evaluation_acc: 0.774\n",
      "0 evaluation_acc: 0.8225\n",
      "0 evaluation_acc: 0.7824\n",
      "0 evaluation_acc: 0.8223\n",
      "0 evaluation_acc: 0.8382\n",
      "0 60 loss: 0.5967562\n",
      "0 evaluation_acc: 0.7988\n",
      "0 evaluation_acc: 0.8459\n",
      "0 evaluation_acc: 0.871\n",
      "0 evaluation_acc: 0.8631\n",
      "0 evaluation_acc: 0.8488\n",
      "0 evaluation_acc: 0.8643\n",
      "0 evaluation_acc: 0.8517\n",
      "0 evaluation_acc: 0.8312\n",
      "0 evaluation_acc: 0.8204\n",
      "0 evaluation_acc: 0.8535\n",
      "0 70 loss: 0.3824068\n",
      "0 evaluation_acc: 0.8238\n",
      "0 evaluation_acc: 0.8183\n",
      "0 evaluation_acc: 0.8418\n",
      "0 evaluation_acc: 0.8406\n",
      "0 evaluation_acc: 0.865\n",
      "0 evaluation_acc: 0.8699\n",
      "0 evaluation_acc: 0.8605\n",
      "0 evaluation_acc: 0.84\n",
      "0 evaluation_acc: 0.8555\n",
      "0 evaluation_acc: 0.8601\n",
      "0 80 loss: 0.55374193\n",
      "0 evaluation_acc: 0.8623\n",
      "0 evaluation_acc: 0.84\n",
      "0 evaluation_acc: 0.8486\n",
      "0 evaluation_acc: 0.8784\n",
      "0 evaluation_acc: 0.8687\n",
      "0 evaluation_acc: 0.853\n",
      "0 evaluation_acc: 0.889\n",
      "0 evaluation_acc: 0.8877\n",
      "0 evaluation_acc: 0.8961\n",
      "0 evaluation_acc: 0.8698\n",
      "0 90 loss: 0.46858785\n",
      "0 evaluation_acc: 0.8684\n",
      "0 evaluation_acc: 0.8907\n",
      "0 evaluation_acc: 0.9119\n",
      "0 evaluation_acc: 0.8881\n",
      "0 evaluation_acc: 0.8736\n",
      "0 evaluation_acc: 0.9037\n",
      "0 evaluation_acc: 0.9182\n",
      "0 evaluation_acc: 0.878\n",
      "0 evaluation_acc: 0.8832\n",
      "0 evaluation_acc: 0.9099\n",
      "0 100 loss: 0.36665815\n",
      "0 evaluation_acc: 0.9151\n",
      "0 evaluation_acc: 0.9021\n",
      "0 evaluation_acc: 0.8911\n",
      "0 evaluation_acc: 0.9007\n",
      "0 evaluation_acc: 0.9167\n",
      "0 evaluation_acc: 0.9176\n",
      "0 evaluation_acc: 0.9072\n",
      "0 evaluation_acc: 0.9036\n",
      "0 evaluation_acc: 0.9014\n",
      "0 evaluation_acc: 0.899\n",
      "0 110 loss: 0.33161455\n",
      "0 evaluation_acc: 0.9068\n",
      "0 evaluation_acc: 0.91\n",
      "0 evaluation_acc: 0.9169\n",
      "0 evaluation_acc: 0.9256\n",
      "0 evaluation_acc: 0.9211\n",
      "0 evaluation_acc: 0.9139\n",
      "0 evaluation_acc: 0.8943\n",
      "0 evaluation_acc: 0.9096\n",
      "0 evaluation_acc: 0.9247\n",
      "0 evaluation_acc: 0.9055\n",
      "0 120 loss: 0.35019898\n",
      "0 evaluation_acc: 0.9102\n",
      "0 evaluation_acc: 0.9241\n",
      "0 evaluation_acc: 0.9158\n",
      "0 evaluation_acc: 0.9086\n",
      "0 evaluation_acc: 0.909\n",
      "0 evaluation_acc: 0.9166\n",
      "0 evaluation_acc: 0.9326\n",
      "0 evaluation_acc: 0.9408\n",
      "0 evaluation_acc: 0.9379\n",
      "0 evaluation_acc: 0.9339\n",
      "0 130 loss: 0.21267414\n",
      "0 evaluation_acc: 0.9312\n",
      "0 evaluation_acc: 0.9291\n",
      "0 evaluation_acc: 0.9333\n",
      "0 evaluation_acc: 0.9404\n",
      "0 evaluation_acc: 0.9418\n",
      "0 evaluation_acc: 0.9386\n",
      "0 evaluation_acc: 0.9372\n",
      "0 evaluation_acc: 0.9366\n",
      "0 evaluation_acc: 0.9423\n",
      "0 evaluation_acc: 0.9443\n",
      "0 140 loss: 0.2685504\n",
      "0 evaluation_acc: 0.9326\n",
      "0 evaluation_acc: 0.9293\n",
      "0 evaluation_acc: 0.9372\n",
      "0 evaluation_acc: 0.9181\n",
      "0 evaluation_acc: 0.9039\n",
      "0 evaluation_acc: 0.9305\n",
      "0 evaluation_acc: 0.9457\n",
      "0 evaluation_acc: 0.9247\n",
      "0 evaluation_acc: 0.9103\n",
      "0 evaluation_acc: 0.9335\n",
      "0 150 loss: 0.20629425\n",
      "0 evaluation_acc: 0.9333\n",
      "0 evaluation_acc: 0.9251\n",
      "0 evaluation_acc: 0.9118\n",
      "0 evaluation_acc: 0.921\n",
      "0 evaluation_acc: 0.935\n",
      "0 evaluation_acc: 0.9257\n",
      "0 evaluation_acc: 0.9099\n",
      "0 evaluation_acc: 0.921\n",
      "0 evaluation_acc: 0.943\n",
      "0 evaluation_acc: 0.936\n",
      "0 160 loss: 0.24871765\n",
      "0 evaluation_acc: 0.9305\n",
      "0 evaluation_acc: 0.9457\n",
      "0 evaluation_acc: 0.9431\n",
      "0 evaluation_acc: 0.9244\n",
      "0 evaluation_acc: 0.9427\n",
      "0 evaluation_acc: 0.9473\n",
      "0 evaluation_acc: 0.9445\n",
      "0 evaluation_acc: 0.9434\n",
      "0 evaluation_acc: 0.9391\n",
      "0 evaluation_acc: 0.9454\n",
      "0 170 loss: 0.1788869\n",
      "0 evaluation_acc: 0.9478\n",
      "0 evaluation_acc: 0.9387\n",
      "0 evaluation_acc: 0.9429\n",
      "0 evaluation_acc: 0.9475\n",
      "0 evaluation_acc: 0.9492\n",
      "0 evaluation_acc: 0.9452\n",
      "0 evaluation_acc: 0.9355\n",
      "0 evaluation_acc: 0.9381\n",
      "0 evaluation_acc: 0.9497\n",
      "0 evaluation_acc: 0.9488\n",
      "0 180 loss: 0.30948192\n",
      "0 evaluation_acc: 0.9477\n",
      "0 evaluation_acc: 0.9487\n",
      "0 evaluation_acc: 0.9505\n",
      "0 evaluation_acc: 0.9464\n",
      "0 evaluation_acc: 0.9403\n",
      "0 evaluation_acc: 0.948\n",
      "0 evaluation_acc: 0.9531\n",
      "0 evaluation_acc: 0.9521\n",
      "0 evaluation_acc: 0.9526\n",
      "0 evaluation_acc: 0.9545\n",
      "0 190 loss: 0.15542217\n",
      "0 evaluation_acc: 0.9581\n",
      "0 evaluation_acc: 0.9526\n",
      "0 evaluation_acc: 0.9472\n",
      "0 evaluation_acc: 0.9485\n",
      "0 evaluation_acc: 0.9518\n",
      "0 evaluation_acc: 0.9516\n",
      "0 evaluation_acc: 0.9486\n",
      "0 evaluation_acc: 0.9465\n",
      "0 evaluation_acc: 0.9425\n",
      "0 evaluation_acc: 0.9393\n",
      "0 200 loss: 0.28076318\n",
      "0 evaluation_acc: 0.9535\n",
      "0 evaluation_acc: 0.9533\n",
      "0 evaluation_acc: 0.949\n",
      "0 evaluation_acc: 0.9503\n",
      "0 evaluation_acc: 0.9489\n",
      "0 evaluation_acc: 0.9451\n",
      "0 evaluation_acc: 0.9528\n",
      "0 evaluation_acc: 0.9522\n",
      "0 evaluation_acc: 0.9459\n",
      "0 evaluation_acc: 0.9516\n",
      "0 210 loss: 0.1944974\n",
      "0 evaluation_acc: 0.9565\n",
      "0 evaluation_acc: 0.947\n",
      "0 evaluation_acc: 0.9387\n",
      "0 evaluation_acc: 0.9507\n",
      "0 evaluation_acc: 0.9588\n",
      "0 evaluation_acc: 0.9501\n",
      "0 evaluation_acc: 0.9466\n",
      "0 evaluation_acc: 0.9484\n",
      "0 evaluation_acc: 0.9445\n",
      "0 evaluation_acc: 0.9532\n",
      "0 220 loss: 0.17373274\n",
      "0 evaluation_acc: 0.952\n",
      "0 evaluation_acc: 0.9439\n",
      "0 evaluation_acc: 0.9431\n",
      "0 evaluation_acc: 0.9416\n",
      "0 evaluation_acc: 0.942\n",
      "0 evaluation_acc: 0.9539\n",
      "0 evaluation_acc: 0.9525\n",
      "0 evaluation_acc: 0.9463\n",
      "0 evaluation_acc: 0.9511\n",
      "0 evaluation_acc: 0.9406\n",
      "0 230 loss: 0.038932897\n",
      "0 evaluation_acc: 0.9321\n",
      "0 evaluation_acc: 0.9478\n",
      "0 evaluation_acc: 0.9403\n",
      "0 evaluation_acc: 0.9428\n",
      "0 evaluation_acc: 0.9562\n",
      "1 0 loss: 0.1808177\n",
      "1 evaluation_acc: 0.9325\n",
      "1 evaluation_acc: 0.8942\n",
      "1 evaluation_acc: 0.9259\n",
      "1 evaluation_acc: 0.9524\n",
      "1 evaluation_acc: 0.947\n",
      "1 evaluation_acc: 0.9388\n",
      "1 evaluation_acc: 0.9326\n",
      "1 evaluation_acc: 0.9351\n",
      "1 evaluation_acc: 0.9393\n",
      "1 evaluation_acc: 0.9517\n",
      "1 10 loss: 0.15993199\n",
      "1 evaluation_acc: 0.9501\n",
      "1 evaluation_acc: 0.9498\n",
      "1 evaluation_acc: 0.9557\n",
      "1 evaluation_acc: 0.9604\n",
      "1 evaluation_acc: 0.9587\n",
      "1 evaluation_acc: 0.9559\n",
      "1 evaluation_acc: 0.9548\n",
      "1 evaluation_acc: 0.9593\n",
      "1 evaluation_acc: 0.9629\n",
      "1 evaluation_acc: 0.9608\n",
      "1 20 loss: 0.22250222\n",
      "1 evaluation_acc: 0.9597\n",
      "1 evaluation_acc: 0.9582\n",
      "1 evaluation_acc: 0.9605\n",
      "1 evaluation_acc: 0.9612\n",
      "1 evaluation_acc: 0.9531\n",
      "1 evaluation_acc: 0.9402\n",
      "1 evaluation_acc: 0.9567\n",
      "1 evaluation_acc: 0.9592\n",
      "1 evaluation_acc: 0.9535\n",
      "1 evaluation_acc: 0.9507\n",
      "1 30 loss: 0.283862\n",
      "1 evaluation_acc: 0.9619\n",
      "1 evaluation_acc: 0.9497\n",
      "1 evaluation_acc: 0.9535\n",
      "1 evaluation_acc: 0.9523\n",
      "1 evaluation_acc: 0.9326\n",
      "1 evaluation_acc: 0.9379\n",
      "1 evaluation_acc: 0.9609\n",
      "1 evaluation_acc: 0.9644\n",
      "1 evaluation_acc: 0.9364\n",
      "1 evaluation_acc: 0.9352\n",
      "1 40 loss: 0.32225266\n",
      "1 evaluation_acc: 0.9647\n",
      "1 evaluation_acc: 0.9445\n",
      "1 evaluation_acc: 0.9165\n",
      "1 evaluation_acc: 0.9366\n",
      "1 evaluation_acc: 0.9382\n",
      "1 evaluation_acc: 0.9261\n",
      "1 evaluation_acc: 0.927\n",
      "1 evaluation_acc: 0.9331\n",
      "1 evaluation_acc: 0.9524\n",
      "1 evaluation_acc: 0.9315\n",
      "1 50 loss: 0.30338722\n",
      "1 evaluation_acc: 0.9341\n",
      "1 evaluation_acc: 0.9403\n",
      "1 evaluation_acc: 0.9317\n",
      "1 evaluation_acc: 0.9308\n",
      "1 evaluation_acc: 0.9448\n",
      "1 evaluation_acc: 0.9481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 evaluation_acc: 0.9422\n",
      "1 evaluation_acc: 0.9339\n",
      "1 evaluation_acc: 0.9384\n",
      "1 evaluation_acc: 0.9553\n",
      "1 60 loss: 0.23070258\n",
      "1 evaluation_acc: 0.9645\n",
      "1 evaluation_acc: 0.9596\n",
      "1 evaluation_acc: 0.9459\n",
      "1 evaluation_acc: 0.9401\n",
      "1 evaluation_acc: 0.9408\n",
      "1 evaluation_acc: 0.9535\n",
      "1 evaluation_acc: 0.9609\n",
      "1 evaluation_acc: 0.9611\n",
      "1 evaluation_acc: 0.9555\n",
      "1 evaluation_acc: 0.9531\n",
      "1 70 loss: 0.11910495\n",
      "1 evaluation_acc: 0.9481\n",
      "1 evaluation_acc: 0.9528\n",
      "1 evaluation_acc: 0.9594\n",
      "1 evaluation_acc: 0.9618\n",
      "1 evaluation_acc: 0.9627\n",
      "1 evaluation_acc: 0.9652\n",
      "1 evaluation_acc: 0.965\n",
      "1 evaluation_acc: 0.9603\n",
      "1 evaluation_acc: 0.9588\n",
      "1 evaluation_acc: 0.9606\n",
      "1 80 loss: 0.15355435\n",
      "1 evaluation_acc: 0.9594\n",
      "1 evaluation_acc: 0.9623\n",
      "1 evaluation_acc: 0.9651\n",
      "1 evaluation_acc: 0.9646\n",
      "1 evaluation_acc: 0.9626\n",
      "1 evaluation_acc: 0.9624\n",
      "1 evaluation_acc: 0.9604\n",
      "1 evaluation_acc: 0.952\n",
      "1 evaluation_acc: 0.9589\n",
      "1 evaluation_acc: 0.9612\n",
      "1 90 loss: 0.135211\n",
      "1 evaluation_acc: 0.9576\n",
      "1 evaluation_acc: 0.9528\n",
      "1 evaluation_acc: 0.9555\n",
      "1 evaluation_acc: 0.9618\n",
      "1 evaluation_acc: 0.9574\n",
      "1 evaluation_acc: 0.9526\n",
      "1 evaluation_acc: 0.9538\n",
      "1 evaluation_acc: 0.9639\n",
      "1 evaluation_acc: 0.9624\n",
      "1 evaluation_acc: 0.9596\n",
      "1 100 loss: 0.15267944\n",
      "1 evaluation_acc: 0.9575\n",
      "1 evaluation_acc: 0.9597\n",
      "1 evaluation_acc: 0.96\n",
      "1 evaluation_acc: 0.9619\n",
      "1 evaluation_acc: 0.9669\n",
      "1 evaluation_acc: 0.9699\n",
      "1 evaluation_acc: 0.9642\n",
      "1 evaluation_acc: 0.9501\n",
      "1 evaluation_acc: 0.9495\n",
      "1 evaluation_acc: 0.9495\n",
      "1 110 loss: 0.21079046\n",
      "1 evaluation_acc: 0.9609\n",
      "1 evaluation_acc: 0.9668\n",
      "1 evaluation_acc: 0.9653\n",
      "1 evaluation_acc: 0.9613\n",
      "1 evaluation_acc: 0.9619\n",
      "1 evaluation_acc: 0.9659\n",
      "1 evaluation_acc: 0.9679\n",
      "1 evaluation_acc: 0.9645\n",
      "1 evaluation_acc: 0.9587\n",
      "1 evaluation_acc: 0.9654\n",
      "1 120 loss: 0.11740303\n",
      "1 evaluation_acc: 0.9688\n",
      "1 evaluation_acc: 0.9677\n",
      "1 evaluation_acc: 0.9689\n",
      "1 evaluation_acc: 0.9701\n",
      "1 evaluation_acc: 0.9675\n",
      "1 evaluation_acc: 0.9674\n",
      "1 evaluation_acc: 0.9669\n",
      "1 evaluation_acc: 0.9665\n",
      "1 evaluation_acc: 0.9648\n",
      "1 evaluation_acc: 0.967\n",
      "1 130 loss: 0.12767273\n",
      "1 evaluation_acc: 0.9701\n",
      "1 evaluation_acc: 0.9681\n",
      "1 evaluation_acc: 0.9678\n",
      "1 evaluation_acc: 0.9662\n",
      "1 evaluation_acc: 0.971\n",
      "1 evaluation_acc: 0.9689\n",
      "1 evaluation_acc: 0.9636\n",
      "1 evaluation_acc: 0.9622\n",
      "1 evaluation_acc: 0.9686\n",
      "1 evaluation_acc: 0.9739\n",
      "1 140 loss: 0.12785223\n",
      "1 evaluation_acc: 0.9719\n",
      "1 evaluation_acc: 0.9701\n",
      "1 evaluation_acc: 0.9688\n",
      "1 evaluation_acc: 0.9686\n",
      "1 evaluation_acc: 0.9709\n",
      "1 evaluation_acc: 0.9724\n",
      "1 evaluation_acc: 0.969\n",
      "1 evaluation_acc: 0.966\n",
      "1 evaluation_acc: 0.9684\n",
      "1 evaluation_acc: 0.9714\n",
      "1 150 loss: 0.095199354\n",
      "1 evaluation_acc: 0.9753\n",
      "1 evaluation_acc: 0.9736\n",
      "1 evaluation_acc: 0.9687\n",
      "1 evaluation_acc: 0.9715\n",
      "1 evaluation_acc: 0.9715\n",
      "1 evaluation_acc: 0.9694\n",
      "1 evaluation_acc: 0.9643\n",
      "1 evaluation_acc: 0.9625\n",
      "1 evaluation_acc: 0.9673\n",
      "1 evaluation_acc: 0.9693\n",
      "1 160 loss: 0.11179885\n",
      "1 evaluation_acc: 0.9719\n",
      "1 evaluation_acc: 0.9725\n",
      "1 evaluation_acc: 0.9752\n",
      "1 evaluation_acc: 0.9745\n",
      "1 evaluation_acc: 0.973\n",
      "1 evaluation_acc: 0.9701\n",
      "1 evaluation_acc: 0.9674\n",
      "1 evaluation_acc: 0.9698\n",
      "1 evaluation_acc: 0.9704\n",
      "1 evaluation_acc: 0.9746\n",
      "1 170 loss: 0.08834974\n",
      "1 evaluation_acc: 0.9745\n",
      "1 evaluation_acc: 0.9747\n",
      "1 evaluation_acc: 0.9732\n",
      "1 evaluation_acc: 0.9736\n",
      "1 evaluation_acc: 0.9729\n",
      "1 evaluation_acc: 0.972\n",
      "1 evaluation_acc: 0.9714\n",
      "1 evaluation_acc: 0.9713\n",
      "1 evaluation_acc: 0.9722\n",
      "1 evaluation_acc: 0.9739\n",
      "1 180 loss: 0.17011024\n",
      "1 evaluation_acc: 0.974\n",
      "1 evaluation_acc: 0.9738\n",
      "1 evaluation_acc: 0.9732\n",
      "1 evaluation_acc: 0.9707\n",
      "1 evaluation_acc: 0.9708\n",
      "1 evaluation_acc: 0.9731\n",
      "1 evaluation_acc: 0.9722\n",
      "1 evaluation_acc: 0.9715\n",
      "1 evaluation_acc: 0.9704\n",
      "1 evaluation_acc: 0.9714\n",
      "1 190 loss: 0.06441961\n",
      "1 evaluation_acc: 0.9704\n",
      "1 evaluation_acc: 0.9711\n",
      "1 evaluation_acc: 0.9737\n",
      "1 evaluation_acc: 0.9748\n",
      "1 evaluation_acc: 0.9739\n",
      "1 evaluation_acc: 0.9705\n",
      "1 evaluation_acc: 0.9663\n",
      "1 evaluation_acc: 0.9664\n",
      "1 evaluation_acc: 0.9692\n",
      "1 evaluation_acc: 0.9692\n",
      "1 200 loss: 0.1347734\n",
      "1 evaluation_acc: 0.9699\n",
      "1 evaluation_acc: 0.9716\n",
      "1 evaluation_acc: 0.9732\n",
      "1 evaluation_acc: 0.9756\n",
      "1 evaluation_acc: 0.9734\n",
      "1 evaluation_acc: 0.9691\n",
      "1 evaluation_acc: 0.9683\n",
      "1 evaluation_acc: 0.9672\n",
      "1 evaluation_acc: 0.9666\n",
      "1 evaluation_acc: 0.9692\n",
      "1 210 loss: 0.12449585\n",
      "1 evaluation_acc: 0.9713\n",
      "1 evaluation_acc: 0.9733\n",
      "1 evaluation_acc: 0.9704\n",
      "1 evaluation_acc: 0.9675\n",
      "1 evaluation_acc: 0.9686\n",
      "1 evaluation_acc: 0.9701\n",
      "1 evaluation_acc: 0.9717\n",
      "1 evaluation_acc: 0.9669\n",
      "1 evaluation_acc: 0.9537\n",
      "1 evaluation_acc: 0.9643\n",
      "1 220 loss: 0.17101738\n",
      "1 evaluation_acc: 0.9715\n",
      "1 evaluation_acc: 0.9707\n",
      "1 evaluation_acc: 0.967\n",
      "1 evaluation_acc: 0.9653\n",
      "1 evaluation_acc: 0.967\n",
      "1 evaluation_acc: 0.9684\n",
      "1 evaluation_acc: 0.9686\n",
      "1 evaluation_acc: 0.9694\n",
      "1 evaluation_acc: 0.9716\n",
      "1 evaluation_acc: 0.9686\n",
      "1 230 loss: 0.0066921543\n",
      "1 evaluation_acc: 0.9608\n",
      "1 evaluation_acc: 0.9672\n",
      "1 evaluation_acc: 0.971\n",
      "1 evaluation_acc: 0.9655\n",
      "1 evaluation_acc: 0.9615\n",
      "2 0 loss: 0.12880617\n",
      "2 evaluation_acc: 0.9649\n",
      "2 evaluation_acc: 0.9725\n",
      "2 evaluation_acc: 0.9716\n",
      "2 evaluation_acc: 0.9691\n",
      "2 evaluation_acc: 0.9722\n",
      "2 evaluation_acc: 0.9659\n",
      "2 evaluation_acc: 0.9509\n",
      "2 evaluation_acc: 0.9505\n",
      "2 evaluation_acc: 0.9611\n",
      "2 evaluation_acc: 0.9716\n",
      "2 10 loss: 0.107578024\n",
      "2 evaluation_acc: 0.9742\n",
      "2 evaluation_acc: 0.9696\n",
      "2 evaluation_acc: 0.9602\n",
      "2 evaluation_acc: 0.9582\n",
      "2 evaluation_acc: 0.9649\n",
      "2 evaluation_acc: 0.975\n",
      "2 evaluation_acc: 0.9774\n",
      "2 evaluation_acc: 0.9747\n",
      "2 evaluation_acc: 0.9742\n",
      "2 evaluation_acc: 0.9735\n",
      "2 20 loss: 0.12135587\n",
      "2 evaluation_acc: 0.9723\n",
      "2 evaluation_acc: 0.9728\n",
      "2 evaluation_acc: 0.9735\n",
      "2 evaluation_acc: 0.9759\n",
      "2 evaluation_acc: 0.976\n",
      "2 evaluation_acc: 0.9743\n",
      "2 evaluation_acc: 0.9728\n",
      "2 evaluation_acc: 0.9729\n",
      "2 evaluation_acc: 0.9737\n",
      "2 evaluation_acc: 0.9743\n",
      "2 30 loss: 0.16061041\n",
      "2 evaluation_acc: 0.976\n",
      "2 evaluation_acc: 0.9754\n",
      "2 evaluation_acc: 0.9741\n",
      "2 evaluation_acc: 0.9757\n",
      "2 evaluation_acc: 0.9761\n",
      "2 evaluation_acc: 0.9747\n",
      "2 evaluation_acc: 0.9707\n",
      "2 evaluation_acc: 0.9768\n",
      "2 evaluation_acc: 0.9777\n",
      "2 evaluation_acc: 0.9689\n",
      "2 40 loss: 0.13772975\n",
      "2 evaluation_acc: 0.9709\n",
      "2 evaluation_acc: 0.9731\n",
      "2 evaluation_acc: 0.9698\n",
      "2 evaluation_acc: 0.9694\n",
      "2 evaluation_acc: 0.974\n",
      "2 evaluation_acc: 0.9734\n",
      "2 evaluation_acc: 0.9544\n",
      "2 evaluation_acc: 0.9434\n",
      "2 evaluation_acc: 0.9732\n",
      "2 evaluation_acc: 0.9604\n",
      "2 50 loss: 0.12245472\n",
      "2 evaluation_acc: 0.9312\n",
      "2 evaluation_acc: 0.9491\n",
      "2 evaluation_acc: 0.9674\n",
      "2 evaluation_acc: 0.9703\n",
      "2 evaluation_acc: 0.963\n",
      "2 evaluation_acc: 0.9592\n",
      "2 evaluation_acc: 0.9685\n",
      "2 evaluation_acc: 0.9725\n",
      "2 evaluation_acc: 0.968\n",
      "2 evaluation_acc: 0.9596\n",
      "2 60 loss: 0.2564271\n",
      "2 evaluation_acc: 0.9658\n",
      "2 evaluation_acc: 0.9744\n",
      "2 evaluation_acc: 0.9735\n",
      "2 evaluation_acc: 0.964\n",
      "2 evaluation_acc: 0.9513\n",
      "2 evaluation_acc: 0.9501\n",
      "2 evaluation_acc: 0.9686\n",
      "2 evaluation_acc: 0.9722\n",
      "2 evaluation_acc: 0.9599\n",
      "2 evaluation_acc: 0.9494\n",
      "2 70 loss: 0.12980984\n",
      "2 evaluation_acc: 0.9515\n",
      "2 evaluation_acc: 0.9603\n",
      "2 evaluation_acc: 0.9657\n",
      "2 evaluation_acc: 0.9667\n",
      "2 evaluation_acc: 0.9696\n",
      "2 evaluation_acc: 0.9746\n",
      "2 evaluation_acc: 0.9737\n",
      "2 evaluation_acc: 0.9663\n",
      "2 evaluation_acc: 0.965\n",
      "2 evaluation_acc: 0.9729\n",
      "2 80 loss: 0.11119488\n",
      "2 evaluation_acc: 0.9748\n",
      "2 evaluation_acc: 0.9781\n",
      "2 evaluation_acc: 0.9781\n",
      "2 evaluation_acc: 0.978\n",
      "2 evaluation_acc: 0.9775\n",
      "2 evaluation_acc: 0.9764\n",
      "2 evaluation_acc: 0.9757\n",
      "2 evaluation_acc: 0.9705\n",
      "2 evaluation_acc: 0.9705\n",
      "2 evaluation_acc: 0.9711\n",
      "2 90 loss: 0.09188749\n",
      "2 evaluation_acc: 0.9723\n",
      "2 evaluation_acc: 0.9747\n",
      "2 evaluation_acc: 0.9751\n",
      "2 evaluation_acc: 0.9768\n",
      "2 evaluation_acc: 0.9777\n",
      "2 evaluation_acc: 0.9767\n",
      "2 evaluation_acc: 0.9754\n",
      "2 evaluation_acc: 0.9768\n",
      "2 evaluation_acc: 0.9781\n",
      "2 evaluation_acc: 0.9784\n",
      "2 100 loss: 0.081394\n",
      "2 evaluation_acc: 0.9779\n",
      "2 evaluation_acc: 0.9785\n",
      "2 evaluation_acc: 0.9789\n",
      "2 evaluation_acc: 0.9793\n",
      "2 evaluation_acc: 0.9785\n",
      "2 evaluation_acc: 0.9801\n",
      "2 evaluation_acc: 0.9797\n",
      "2 evaluation_acc: 0.979\n",
      "2 evaluation_acc: 0.9771\n",
      "2 evaluation_acc: 0.9737\n",
      "2 110 loss: 0.117820114\n",
      "2 evaluation_acc: 0.9761\n",
      "2 evaluation_acc: 0.9784\n",
      "2 evaluation_acc: 0.9788\n",
      "2 evaluation_acc: 0.9782\n",
      "2 evaluation_acc: 0.9781\n",
      "2 evaluation_acc: 0.9789\n",
      "2 evaluation_acc: 0.9789\n",
      "2 evaluation_acc: 0.9793\n",
      "2 evaluation_acc: 0.979\n",
      "2 evaluation_acc: 0.9808\n",
      "2 120 loss: 0.07266708\n",
      "2 evaluation_acc: 0.9822\n",
      "2 evaluation_acc: 0.9789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 evaluation_acc: 0.9796\n",
      "2 evaluation_acc: 0.9802\n",
      "2 evaluation_acc: 0.9814\n",
      "2 evaluation_acc: 0.9811\n",
      "2 evaluation_acc: 0.9785\n",
      "2 evaluation_acc: 0.9727\n",
      "2 evaluation_acc: 0.9678\n",
      "2 evaluation_acc: 0.9733\n",
      "2 130 loss: 0.13720977\n",
      "2 evaluation_acc: 0.9799\n",
      "2 evaluation_acc: 0.9773\n",
      "2 evaluation_acc: 0.9672\n",
      "2 evaluation_acc: 0.9611\n",
      "2 evaluation_acc: 0.9744\n",
      "2 evaluation_acc: 0.982\n",
      "2 evaluation_acc: 0.9735\n",
      "2 evaluation_acc: 0.9593\n",
      "2 evaluation_acc: 0.9663\n",
      "2 evaluation_acc: 0.9776\n",
      "2 140 loss: 0.075022824\n",
      "2 evaluation_acc: 0.9804\n",
      "2 evaluation_acc: 0.9771\n",
      "2 evaluation_acc: 0.9706\n",
      "2 evaluation_acc: 0.9642\n",
      "2 evaluation_acc: 0.9702\n",
      "2 evaluation_acc: 0.9776\n",
      "2 evaluation_acc: 0.9776\n",
      "2 evaluation_acc: 0.9717\n",
      "2 evaluation_acc: 0.9641\n",
      "2 evaluation_acc: 0.9689\n",
      "2 150 loss: 0.134992\n",
      "2 evaluation_acc: 0.9787\n",
      "2 evaluation_acc: 0.982\n",
      "2 evaluation_acc: 0.9782\n",
      "2 evaluation_acc: 0.9741\n",
      "2 evaluation_acc: 0.9738\n",
      "2 evaluation_acc: 0.9753\n",
      "2 evaluation_acc: 0.9745\n",
      "2 evaluation_acc: 0.973\n",
      "2 evaluation_acc: 0.9742\n",
      "2 evaluation_acc: 0.9754\n",
      "2 160 loss: 0.087138936\n",
      "2 evaluation_acc: 0.9781\n",
      "2 evaluation_acc: 0.9792\n",
      "2 evaluation_acc: 0.9806\n",
      "2 evaluation_acc: 0.9807\n",
      "2 evaluation_acc: 0.9801\n",
      "2 evaluation_acc: 0.9801\n",
      "2 evaluation_acc: 0.9792\n",
      "2 evaluation_acc: 0.9778\n",
      "2 evaluation_acc: 0.9753\n",
      "2 evaluation_acc: 0.9776\n",
      "2 170 loss: 0.07031297\n",
      "2 evaluation_acc: 0.9791\n",
      "2 evaluation_acc: 0.9792\n",
      "2 evaluation_acc: 0.9797\n",
      "2 evaluation_acc: 0.9798\n",
      "2 evaluation_acc: 0.979\n",
      "2 evaluation_acc: 0.9786\n",
      "2 evaluation_acc: 0.9782\n",
      "2 evaluation_acc: 0.978\n",
      "2 evaluation_acc: 0.9803\n",
      "2 evaluation_acc: 0.9797\n",
      "2 180 loss: 0.11887949\n",
      "2 evaluation_acc: 0.9792\n",
      "2 evaluation_acc: 0.9782\n",
      "2 evaluation_acc: 0.9782\n",
      "2 evaluation_acc: 0.9786\n",
      "2 evaluation_acc: 0.9773\n",
      "2 evaluation_acc: 0.9781\n",
      "2 evaluation_acc: 0.9783\n",
      "2 evaluation_acc: 0.9768\n",
      "2 evaluation_acc: 0.9764\n",
      "2 evaluation_acc: 0.9772\n",
      "2 190 loss: 0.05542042\n",
      "2 evaluation_acc: 0.9777\n",
      "2 evaluation_acc: 0.9795\n",
      "2 evaluation_acc: 0.9803\n",
      "2 evaluation_acc: 0.9816\n",
      "2 evaluation_acc: 0.9806\n",
      "2 evaluation_acc: 0.9803\n",
      "2 evaluation_acc: 0.9802\n",
      "2 evaluation_acc: 0.9785\n",
      "2 evaluation_acc: 0.9767\n",
      "2 evaluation_acc: 0.9766\n",
      "2 200 loss: 0.08251473\n",
      "2 evaluation_acc: 0.9765\n",
      "2 evaluation_acc: 0.9805\n",
      "2 evaluation_acc: 0.9818\n",
      "2 evaluation_acc: 0.9828\n",
      "2 evaluation_acc: 0.9795\n",
      "2 evaluation_acc: 0.9766\n",
      "2 evaluation_acc: 0.9797\n",
      "2 evaluation_acc: 0.9775\n",
      "2 evaluation_acc: 0.974\n",
      "2 evaluation_acc: 0.9731\n",
      "2 210 loss: 0.09941054\n",
      "2 evaluation_acc: 0.974\n",
      "2 evaluation_acc: 0.9796\n",
      "2 evaluation_acc: 0.9819\n",
      "2 evaluation_acc: 0.982\n",
      "2 evaluation_acc: 0.9804\n",
      "2 evaluation_acc: 0.9787\n",
      "2 evaluation_acc: 0.9764\n",
      "2 evaluation_acc: 0.9784\n",
      "2 evaluation_acc: 0.9759\n",
      "2 evaluation_acc: 0.9764\n",
      "2 220 loss: 0.10815147\n",
      "2 evaluation_acc: 0.9752\n",
      "2 evaluation_acc: 0.9774\n",
      "2 evaluation_acc: 0.9779\n",
      "2 evaluation_acc: 0.9787\n",
      "2 evaluation_acc: 0.9782\n",
      "2 evaluation_acc: 0.9783\n",
      "2 evaluation_acc: 0.979\n",
      "2 evaluation_acc: 0.9787\n",
      "2 evaluation_acc: 0.9791\n",
      "2 evaluation_acc: 0.9815\n",
      "2 230 loss: 0.008082139\n",
      "2 evaluation_acc: 0.9807\n",
      "2 evaluation_acc: 0.9789\n",
      "2 evaluation_acc: 0.9775\n",
      "2 evaluation_acc: 0.9755\n",
      "2 evaluation_acc: 0.978\n",
      "3 0 loss: 0.0804978\n",
      "3 evaluation_acc: 0.9756\n",
      "3 evaluation_acc: 0.9747\n",
      "3 evaluation_acc: 0.9703\n",
      "3 evaluation_acc: 0.9753\n",
      "3 evaluation_acc: 0.983\n",
      "3 evaluation_acc: 0.9817\n",
      "3 evaluation_acc: 0.9705\n",
      "3 evaluation_acc: 0.9588\n",
      "3 evaluation_acc: 0.9618\n",
      "3 evaluation_acc: 0.9709\n",
      "3 10 loss: 0.13610922\n",
      "3 evaluation_acc: 0.979\n",
      "3 evaluation_acc: 0.9773\n",
      "3 evaluation_acc: 0.9716\n",
      "3 evaluation_acc: 0.971\n",
      "3 evaluation_acc: 0.9756\n",
      "3 evaluation_acc: 0.9782\n",
      "3 evaluation_acc: 0.9781\n",
      "3 evaluation_acc: 0.9766\n",
      "3 evaluation_acc: 0.9795\n",
      "3 evaluation_acc: 0.9826\n",
      "3 20 loss: 0.096379\n",
      "3 evaluation_acc: 0.9822\n",
      "3 evaluation_acc: 0.9788\n",
      "3 evaluation_acc: 0.9762\n",
      "3 evaluation_acc: 0.9768\n",
      "3 evaluation_acc: 0.9779\n",
      "3 evaluation_acc: 0.9763\n",
      "3 evaluation_acc: 0.9761\n",
      "3 evaluation_acc: 0.9759\n",
      "3 evaluation_acc: 0.9775\n",
      "3 evaluation_acc: 0.9791\n",
      "3 30 loss: 0.13006155\n",
      "3 evaluation_acc: 0.9805\n",
      "3 evaluation_acc: 0.9782\n",
      "3 evaluation_acc: 0.9757\n",
      "3 evaluation_acc: 0.9787\n",
      "3 evaluation_acc: 0.982\n",
      "3 evaluation_acc: 0.9814\n",
      "3 evaluation_acc: 0.9779\n",
      "3 evaluation_acc: 0.9799\n",
      "3 evaluation_acc: 0.9815\n",
      "3 evaluation_acc: 0.9798\n",
      "3 40 loss: 0.08087631\n",
      "3 evaluation_acc: 0.9754\n",
      "3 evaluation_acc: 0.9735\n",
      "3 evaluation_acc: 0.9752\n",
      "3 evaluation_acc: 0.9766\n",
      "3 evaluation_acc: 0.9793\n",
      "3 evaluation_acc: 0.9814\n",
      "3 evaluation_acc: 0.9823\n",
      "3 evaluation_acc: 0.9796\n",
      "3 evaluation_acc: 0.9802\n",
      "3 evaluation_acc: 0.9809\n",
      "3 50 loss: 0.04774744\n",
      "3 evaluation_acc: 0.9773\n",
      "3 evaluation_acc: 0.9712\n",
      "3 evaluation_acc: 0.9664\n",
      "3 evaluation_acc: 0.9709\n",
      "3 evaluation_acc: 0.9764\n",
      "3 evaluation_acc: 0.9799\n",
      "3 evaluation_acc: 0.9814\n",
      "3 evaluation_acc: 0.9816\n",
      "3 evaluation_acc: 0.9803\n",
      "3 evaluation_acc: 0.9822\n",
      "3 60 loss: 0.12195086\n",
      "3 evaluation_acc: 0.9827\n",
      "3 evaluation_acc: 0.9823\n",
      "3 evaluation_acc: 0.9814\n",
      "3 evaluation_acc: 0.9801\n",
      "3 evaluation_acc: 0.9781\n",
      "3 evaluation_acc: 0.9776\n",
      "3 evaluation_acc: 0.982\n",
      "3 evaluation_acc: 0.9832\n",
      "3 evaluation_acc: 0.9827\n",
      "3 evaluation_acc: 0.9815\n",
      "3 70 loss: 0.08473893\n",
      "3 evaluation_acc: 0.9825\n",
      "3 evaluation_acc: 0.9822\n",
      "3 evaluation_acc: 0.9813\n",
      "3 evaluation_acc: 0.9801\n",
      "3 evaluation_acc: 0.9825\n",
      "3 evaluation_acc: 0.9828\n",
      "3 evaluation_acc: 0.9836\n",
      "3 evaluation_acc: 0.985\n",
      "3 evaluation_acc: 0.9828\n",
      "3 evaluation_acc: 0.9814\n",
      "3 80 loss: 0.08802048\n",
      "3 evaluation_acc: 0.9812\n",
      "3 evaluation_acc: 0.9809\n",
      "3 evaluation_acc: 0.9828\n",
      "3 evaluation_acc: 0.9842\n",
      "3 evaluation_acc: 0.9839\n",
      "3 evaluation_acc: 0.9836\n",
      "3 evaluation_acc: 0.9832\n",
      "3 evaluation_acc: 0.9809\n",
      "3 evaluation_acc: 0.9814\n",
      "3 evaluation_acc: 0.9808\n",
      "3 90 loss: 0.053191908\n",
      "3 evaluation_acc: 0.9819\n",
      "3 evaluation_acc: 0.9805\n",
      "3 evaluation_acc: 0.9772\n",
      "3 evaluation_acc: 0.9788\n",
      "3 evaluation_acc: 0.9807\n",
      "3 evaluation_acc: 0.9809\n",
      "3 evaluation_acc: 0.9826\n",
      "3 evaluation_acc: 0.9836\n",
      "3 evaluation_acc: 0.9829\n",
      "3 evaluation_acc: 0.9807\n",
      "3 100 loss: 0.06532905\n",
      "3 evaluation_acc: 0.9786\n",
      "3 evaluation_acc: 0.981\n",
      "3 evaluation_acc: 0.9826\n",
      "3 evaluation_acc: 0.9838\n",
      "3 evaluation_acc: 0.9843\n",
      "3 evaluation_acc: 0.9849\n",
      "3 evaluation_acc: 0.9841\n",
      "3 evaluation_acc: 0.9843\n",
      "3 evaluation_acc: 0.9843\n",
      "3 evaluation_acc: 0.9828\n",
      "3 110 loss: 0.06416303\n",
      "3 evaluation_acc: 0.9827\n",
      "3 evaluation_acc: 0.9827\n",
      "3 evaluation_acc: 0.983\n",
      "3 evaluation_acc: 0.982\n",
      "3 evaluation_acc: 0.9817\n",
      "3 evaluation_acc: 0.9818\n",
      "3 evaluation_acc: 0.9822\n",
      "3 evaluation_acc: 0.9828\n",
      "3 evaluation_acc: 0.9834\n",
      "3 evaluation_acc: 0.9843\n",
      "3 120 loss: 0.056284472\n",
      "3 evaluation_acc: 0.9853\n",
      "3 evaluation_acc: 0.9858\n",
      "3 evaluation_acc: 0.9863\n",
      "3 evaluation_acc: 0.9862\n",
      "3 evaluation_acc: 0.985\n",
      "3 evaluation_acc: 0.9859\n",
      "3 evaluation_acc: 0.9833\n",
      "3 evaluation_acc: 0.9802\n",
      "3 evaluation_acc: 0.9764\n",
      "3 evaluation_acc: 0.9778\n",
      "3 130 loss: 0.12196799\n",
      "3 evaluation_acc: 0.9828\n",
      "3 evaluation_acc: 0.984\n",
      "3 evaluation_acc: 0.9791\n",
      "3 evaluation_acc: 0.9746\n",
      "3 evaluation_acc: 0.9785\n",
      "3 evaluation_acc: 0.9854\n",
      "3 evaluation_acc: 0.9834\n",
      "3 evaluation_acc: 0.977\n",
      "3 evaluation_acc: 0.9756\n",
      "3 evaluation_acc: 0.9821\n",
      "3 140 loss: 0.061303932\n",
      "3 evaluation_acc: 0.9842\n",
      "3 evaluation_acc: 0.9864\n",
      "3 evaluation_acc: 0.9837\n",
      "3 evaluation_acc: 0.978\n",
      "3 evaluation_acc: 0.9746\n",
      "3 evaluation_acc: 0.9794\n",
      "3 evaluation_acc: 0.9823\n",
      "3 evaluation_acc: 0.9801\n",
      "3 evaluation_acc: 0.9775\n",
      "3 evaluation_acc: 0.9744\n",
      "3 150 loss: 0.12621431\n",
      "3 evaluation_acc: 0.9804\n",
      "3 evaluation_acc: 0.9856\n",
      "3 evaluation_acc: 0.9867\n",
      "3 evaluation_acc: 0.9862\n",
      "3 evaluation_acc: 0.984\n",
      "3 evaluation_acc: 0.982\n",
      "3 evaluation_acc: 0.9789\n",
      "3 evaluation_acc: 0.9768\n",
      "3 evaluation_acc: 0.978\n",
      "3 evaluation_acc: 0.9818\n",
      "3 160 loss: 0.056870095\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-3)\n",
    "criteon = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "acc_meter = keras.metrics.Accuracy()\n",
    "\n",
    "for epoch in range(100):\n",
    "    \n",
    "    for step, (x, y) in enumerate(db_train):\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            logits=model(x)\n",
    "            loss=criteon(tf.one_hot(y, depth=10), logits)\n",
    "            \n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        \n",
    "        if step % 10 == 0:\n",
    "            print(epoch, step, 'loss:', loss.numpy())\n",
    "            \n",
    "        acc_meter.reset_states()\n",
    "        for x, y in db_test:\n",
    "            logits = model(x, training=False)\n",
    "            pred = tf.argmax(logits, axis=1)\n",
    "            acc_meter.update_state(y, pred)\n",
    "            \n",
    "        print(epoch, 'evaluation_acc:', acc_meter.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
