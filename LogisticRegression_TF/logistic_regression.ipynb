{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bitdeeplearningcondaa9daeba634b04f9786f392bcf0f53381",
   "display_name": "Python 3.6.10 64-bit ('deeplearning': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://builtin.com/data-science/guide-logistic-regression-tensorflow-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "num_features = 784\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
    "\n",
    "x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])\n",
    "\n",
    "x_train, x_test = x_train / 255., x_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10 \n",
    "learning_rate = 0.01\n",
    "training_steps = 1000\n",
    "batch_size = 256\n",
    "display_step = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-95528b11c380>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "\n",
    "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight of shape [784, 10], the 28*28 image features, and a total number of classes.\n",
    "\n",
    "W = tf.Variable( tf.ones([num_features, num_classes] ), name='weight')\n",
    "\n",
    "# Bias of shape [10], the total number of classes\n",
    "\n",
    "b = tf.Variable(tf.zeros([num_classes]), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(x):\n",
    "\n",
    "    return tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "def cross_entropy(y_pred, y_true):\n",
    "\n",
    "    y_true = tf.one_hot(y_true, depth=num_classes)\n",
    "\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)\n",
    "\n",
    "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    # Predicted class is the index of the highest score in prediction vector\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
    "\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "optimizer = tf.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optimization(x, y):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        pred = logistic_regression(x)\n",
    "        loss = cross_entropy(pred, y)\n",
    "\n",
    "    # Compute gradients\n",
    "\n",
    "    gradients = tape.gradient(loss, [W, b])\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "step: 10, loss: 691.529480, accuracy: 0.796875\nstep: 20, loss: 620.176941, accuracy: 0.746094\nstep: 30, loss: 565.910522, accuracy: 0.820312\nstep: 40, loss: 631.329102, accuracy: 0.800781\nstep: 50, loss: 229.691238, accuracy: 0.773438\nstep: 60, loss: 153.474747, accuracy: 0.851562\nstep: 70, loss: 372.663177, accuracy: 0.750000\nstep: 80, loss: 291.371521, accuracy: 0.718750\nstep: 90, loss: 79.961983, accuracy: 0.925781\nstep: 100, loss: 121.093758, accuracy: 0.902344\nstep: 110, loss: 167.074066, accuracy: 0.828125\nstep: 120, loss: 120.750793, accuracy: 0.863281\nstep: 130, loss: 124.643440, accuracy: 0.859375\nstep: 140, loss: 211.851639, accuracy: 0.773438\nstep: 150, loss: 38.695190, accuracy: 0.957031\nstep: 160, loss: 130.647797, accuracy: 0.875000\nstep: 170, loss: 99.927315, accuracy: 0.886719\nstep: 180, loss: 157.946732, accuracy: 0.851562\nstep: 190, loss: 74.387283, accuracy: 0.929688\nstep: 200, loss: 78.223686, accuracy: 0.917969\nstep: 210, loss: 73.908073, accuracy: 0.921875\nstep: 220, loss: 64.382339, accuracy: 0.906250\nstep: 230, loss: 108.037827, accuracy: 0.902344\nstep: 240, loss: 92.027748, accuracy: 0.929688\nstep: 250, loss: 55.228554, accuracy: 0.933594\nstep: 260, loss: 60.687107, accuracy: 0.953125\nstep: 270, loss: 88.491150, accuracy: 0.871094\nstep: 280, loss: 68.907913, accuracy: 0.929688\nstep: 290, loss: 60.507408, accuracy: 0.910156\nstep: 300, loss: 99.564346, accuracy: 0.898438\nstep: 310, loss: 106.140686, accuracy: 0.890625\nstep: 320, loss: 60.275864, accuracy: 0.914062\nstep: 330, loss: 69.330795, accuracy: 0.933594\nstep: 340, loss: 120.442497, accuracy: 0.878906\nstep: 350, loss: 95.469727, accuracy: 0.910156\nstep: 360, loss: 59.206612, accuracy: 0.929688\nstep: 370, loss: 598.457886, accuracy: 0.828125\nstep: 380, loss: 84.456284, accuracy: 0.937500\nstep: 390, loss: 53.258713, accuracy: 0.929688\nstep: 400, loss: 47.529175, accuracy: 0.945312\nstep: 410, loss: 77.627563, accuracy: 0.906250\nstep: 420, loss: 642.739746, accuracy: 0.644531\nstep: 430, loss: 86.639465, accuracy: 0.902344\nstep: 440, loss: 72.563072, accuracy: 0.898438\nstep: 450, loss: 93.318619, accuracy: 0.921875\nstep: 460, loss: 69.395309, accuracy: 0.933594\nstep: 470, loss: 62.008385, accuracy: 0.925781\nstep: 480, loss: 97.992859, accuracy: 0.898438\nstep: 490, loss: 76.515709, accuracy: 0.937500\nstep: 500, loss: 91.890953, accuracy: 0.921875\nstep: 510, loss: 82.465714, accuracy: 0.898438\nstep: 520, loss: 99.117500, accuracy: 0.925781\nstep: 530, loss: 139.828583, accuracy: 0.878906\nstep: 540, loss: 275.316711, accuracy: 0.789062\nstep: 550, loss: 119.777252, accuracy: 0.851562\nstep: 560, loss: 64.141655, accuracy: 0.929688\nstep: 570, loss: 61.922878, accuracy: 0.921875\nstep: 580, loss: 134.200012, accuracy: 0.906250\nstep: 590, loss: 91.004623, accuracy: 0.894531\nstep: 600, loss: 80.930038, accuracy: 0.917969\nstep: 610, loss: 76.238373, accuracy: 0.910156\nstep: 620, loss: 72.931450, accuracy: 0.921875\nstep: 630, loss: 80.703957, accuracy: 0.917969\nstep: 640, loss: 163.350800, accuracy: 0.835938\nstep: 650, loss: 146.581299, accuracy: 0.859375\nstep: 660, loss: 80.974945, accuracy: 0.886719\nstep: 670, loss: 73.167969, accuracy: 0.902344\nstep: 680, loss: 39.907967, accuracy: 0.964844\nstep: 690, loss: 127.028534, accuracy: 0.890625\nstep: 700, loss: 24.628792, accuracy: 0.968750\nstep: 710, loss: 52.785961, accuracy: 0.925781\nstep: 720, loss: 50.713413, accuracy: 0.949219\nstep: 730, loss: 176.333649, accuracy: 0.804688\nstep: 740, loss: 110.594727, accuracy: 0.875000\nstep: 750, loss: 66.306099, accuracy: 0.917969\nstep: 760, loss: 55.426479, accuracy: 0.941406\nstep: 770, loss: 125.944611, accuracy: 0.898438\nstep: 780, loss: 67.915077, accuracy: 0.902344\nstep: 790, loss: 38.267532, accuracy: 0.949219\nstep: 800, loss: 50.787952, accuracy: 0.953125\nstep: 810, loss: 63.884121, accuracy: 0.925781\nstep: 820, loss: 393.887573, accuracy: 0.828125\nstep: 830, loss: 63.655926, accuracy: 0.933594\nstep: 840, loss: 57.822086, accuracy: 0.937500\nstep: 850, loss: 89.061195, accuracy: 0.921875\nstep: 860, loss: 46.666031, accuracy: 0.945312\nstep: 870, loss: 193.407227, accuracy: 0.804688\nstep: 880, loss: 68.332840, accuracy: 0.933594\nstep: 890, loss: 97.608490, accuracy: 0.910156\nstep: 900, loss: 160.496201, accuracy: 0.878906\nstep: 910, loss: 81.672668, accuracy: 0.929688\nstep: 920, loss: 52.431129, accuracy: 0.945312\nstep: 930, loss: 46.791588, accuracy: 0.945312\nstep: 940, loss: 48.768421, accuracy: 0.941406\nstep: 950, loss: 64.830879, accuracy: 0.941406\nstep: 960, loss: 48.125423, accuracy: 0.921875\nstep: 970, loss: 67.318840, accuracy: 0.914062\nstep: 980, loss: 46.114170, accuracy: 0.957031\nstep: 990, loss: 70.072716, accuracy: 0.925781\nstep: 1000, loss: 69.932411, accuracy: 0.937500\n"
    }
   ],
   "source": [
    "for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):\n",
    "\n",
    "    run_optimization(batch_x, batch_y)\n",
    "\n",
    "    if step % 10 == 0:\n",
    "\n",
    "        pred = logistic_regression(batch_x)\n",
    "\n",
    "        loss = cross_entropy(pred, batch_y)\n",
    "\n",
    "        acc = accuracy(pred, batch_y)\n",
    "\n",
    "        print(\"step: %i, loss: %f, accuracy: %f\" % (step, loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Test Accuracy: 0.915500\n"
    }
   ],
   "source": [
    "pred = logistic_regression(x_test)\n",
    "\n",
    "print(\"Test Accuracy: %f\" % accuracy(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}